# -*- coding: utf-8 -*-
"""ImagingPhysics_penguins.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bkuyolSJ0Mybnz9xzCx9MtbJhMup70dC

## SVM Classification Approach on Penguin Dataset


The dataset is: from Kaggle web page
https://www.kaggle.com/datasets/larsen0966/penguins
"""

# Commented out IPython magic to ensure Python compatibility.
# Packages for analysing
import pandas as pd
import numpy as np
from sklearn import svm

# Packages for visualising
import matplotlib.pyplot as plt
import seaborn as sns; sns.set(font_scale=1.2)

# Allows charts to appear in the notebook
# %matplotlib inline

# Pickle package
import pickle

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/penguins.csv.xls', sep=',')

df

Samplesize = 4
print(df.groupby('species', as_index=False).apply(lambda array: array.loc[np.random.choice(array.index, Samplesize, False),:]))

print(df.groupby('sex', as_index=False).apply(lambda array: array.loc[np.random.choice(array.index, Samplesize, False),:]))

sns.lmplot(x='bill_depth_mm', y='bill_length_mm', data=df, hue='species', palette='Set1', fit_reg=False, scatter_kws={"s":70})

# Identify the type to exclude
type_to_exclude = 'Chinstrap'

# Create the logical condition
condition = df['species'] != type_to_exclude

# Filter the dataset
filtered_data = df[condition]

# Drop NaN or None or -Inf values
filtered_data = filtered_data.dropna()

# Print the filtered dataset
print(filtered_data)

sns.lmplot(x='bill_length_mm', y='bill_depth_mm', data=filtered_data, hue='species', palette='Set1', fit_reg=False, scatter_kws={"s":70})

features = filtered_data[['bill_length_mm', 'bill_depth_mm']].values
species_label = np.where(filtered_data['species']=='Adelie', 0,1)

# Feature names
all_features = filtered_data.columns.values[1:].tolist()
all_features

""" For simplicity on visualisation, i.e. 2D plotting, only 2 features will be shown, instead of `all_features`

"""

# Fit the SVM model
model = svm.SVC(kernel='linear')
model.fit(features, species_label)

# Get the separating hyperplane
w = model.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(30, 60)
yy = a * xx - (model.intercept_[0]) / w[1]

# Plot the parallels to the separating hyperplane that pass through the support vectors
b = model.support_vectors_[0]
yy_down = a * xx + (b[1] - a * b[0])
b = model.support_vectors_[-1]
yy_up = a * xx + (b[1] - a * b[0])

# Plot the hyperplane
sns.lmplot(x='bill_length_mm', y='bill_depth_mm',
           data=filtered_data,
           hue='species', palette='Set1', fit_reg=False, scatter_kws={"s": 70})
plt.plot(xx, yy, linewidth=2, color='black');

# Look at the margins and support vectors
sns.lmplot(x='bill_length_mm', y='bill_depth_mm', data=filtered_data, hue='species', palette='Set1', fit_reg=False, scatter_kws={"s": 70})
plt.plot(xx, yy, linewidth=2, color='black')
plt.plot(xx, yy_down, 'k--')
plt.plot(xx, yy_up, 'k--')
plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],
            s=80, facecolors='none');

"""> **Note:** There is this `C Parameter` that allows us to make some misclassification. For instance the Gentoo guy in the middle of the `Margins` or (~44, ~17) on the map is misclassified. Here C parameter is by default `C=1` under `model.SVC()`method. Here C in SVC is reffered to "Classifier"
"""

def which_specie(bill_length, bill_depth):
  if(model.predict([[bill_length, bill_depth]])) == 0:
    print('That\'s an Adelie Penguin')
  else:
    print('That\'s a Gentoo Penguin')

which_specie(50,20)

"""## Soft Margin and Hard Margin

By changing value of C parameter we can change the priority of our classification. Soft Margin is mostly used in the real life applications.

To give the soft margin example here:
"""

# Fit the SVM model & Change C parameter to Lower value
model = svm.SVC(kernel='linear', C=2**-5) # Soft Margin
model.fit(features, species_label)

# Get the separating hyperplane
w = model.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(30, 60)
yy = a * xx - (model.intercept_[0]) / w[1]

# Plot the parallels to the separating hyperplane that pass through the support vectors
b = model.support_vectors_[0]
yy_down = a * xx + (b[1] - a * b[0])
b = model.support_vectors_[-1]
yy_up = a * xx + (b[1] - a * b[0])

# Plot the hyperplane
sns.lmplot(x='bill_length_mm', y='bill_depth_mm', data=filtered_data, hue='species', palette='Set1', fit_reg=False, scatter_kws={"s": 70})
plt.plot(xx, yy, linewidth=2, color='black');

which_specie(50,20)

# Fit the SVM model & Change C parameter to Higher value
model = svm.SVC(kernel='linear', C=2**5) # "Hard" Margin
model.fit(features, species_label)

# Get the separating hyperplane
w = model.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(30, 60)
yy = a * xx - (model.intercept_[0]) / w[1]

# Plot the parallels to the separating hyperplane that pass through the support vectors
b = model.support_vectors_[0]
yy_down = a * xx + (b[1] - a * b[0])
b = model.support_vectors_[-1]
yy_up = a * xx + (b[1] - a * b[0])

# Plot the hyperplane
sns.lmplot(x='bill_length_mm', y='bill_depth_mm', data=filtered_data, hue='species', palette='Set1', fit_reg=False, scatter_kws={"s": 70})
plt.plot(xx, yy, linewidth=2, color='black');

which_specie(50,20)

"""## Higher Dimensions"""

three_features = filtered_data[['bill_length_mm', 'bill_depth_mm', 'body_mass_g']].values
# Fit the SVM model
model = svm.SVC(kernel='linear')
model.fit(three_features, species_label)

from mpl_toolkits.mplot3d import Axes3D

# Get the separating hyperplane
w = model.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(min(three_features[:, 0]), max(three_features[:, 0]), 200)
yy = np.linspace(min(three_features[:, 1]), max(three_features[:, 1]), 200)
xx, yy = np.meshgrid(xx, yy)
zz = (-w[0] * xx - w[1] * yy - model.intercept_[0]) / w[2]

# Plot the separating hyperplane
fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection='3d')

ax.plot_surface(xx, yy, zz, alpha=0.5, color='gray')

# Plot the data points
scatter = ax.scatter(three_features[:, 0], three_features[:, 1], three_features[:, 2], c=species_label, cmap='seismic', edgecolor='g', s=60)
legend = ax.legend(*scatter.legend_elements(), title="species")
ax.add_artist(legend)

# Set labels
ax.set_xlabel('bill_length_mm')
ax.set_ylabel('bill_depth_mm')
ax.set_zlabel('body_mass_g')

# Create multiple static views by rotating the plot
for angle in range(0, 180, 10):
    ax.view_init(elev=20, azim=angle)
    plt.draw()
    plt.pause(0.1)  # Pause to allow the plot to be rendered

plt.show()

def which_specie(bill_length, bill_depth, body_mass):
  if(model.predict([[bill_length, bill_depth, body_mass]])) == 0:
    print('That\'s an Adelie Penguin')
  else:
    print('That\'s a Gentoo Penguin')

which_specie(50, 16, 6000)

which_specie(45,18,3000)

which_specie(40, 17, 5000)

"""## Multi-Class Applications

SVM can be applied for more than 2 classes. Here, all of 3 types of penguins will be classified:
"""

# Eliminate all None, Inf, NaN values to get a mathematical result
penguin_species = df.dropna()
bill_features = penguin_species[['bill_length_mm', 'bill_depth_mm']].values
all_species = np.where(
    penguin_species['species'] == 'Adelie', 0,
    np.where(penguin_species['species'] == 'Gentoo', 1, 2)
)

# Observe what we got
print(penguin_species)

# Fit the SVM model
# Add "decision_function_shape" feature of SVC to make 2+ classification
# one-verseus-rest instead of ovo
model = svm.SVC(kernel='linear', decision_function_shape='ovr')
# put all the penguins inside to the model
model.fit(bill_features, all_species)

sns.lmplot(x='bill_length_mm', y='bill_depth_mm', data=penguin_species, hue='species', palette='Set1', fit_reg=False, scatter_kws={"s": 70})

# Get the separating hyperplanes for each class
for i in range(3):
  w = model.coef_[i]  # Get the coefficient vector for class i
  a = -w[0] / w[1]  # Calculate the slope for class i
  xx = np.linspace(30, 60)  # Generate a range of values for the x-axis
  yy = a * xx - (model.intercept_[i]) / w[1]  # Calculate the y-values for the hyperplane of class i

  # Plot the parallels to the separating hyperplane that pass through the support vectors for class i
  b = model.support_vectors_[i]  # Get the support vector for class i
  yy_down = a * xx + (b[1] - a * b[0])  # Calculate the y-value for the upper parallel line
  b = model.support_vectors_[(i + 1) % 3]  # Get the support vector for the next class
  yy_up = a * xx + (b[1] - a * b[0])  # Calculate the y-value for the lower parallel line

  # Plot the hyperplane for class i
  plt.plot(xx, yy, linewidth=2, label=penguin_species['species'].unique()[i])
  plt.plot(xx, yy_down, linewidth=1, color='black', linestyle='--')
  plt.plot(xx, yy_up, linewidth=1, color='black', linestyle='--')

plt.show();

def which_species(bill_length, bill_depth):
  if(model.predict([[bill_length, bill_depth]])) == 0:
    print('That\'s an Adelie Penguin')
  elif(model.predict([[bill_length, bill_depth]])) == 1:
    print('That\'s a Gentoo Penguin')
  else: print('That\'s a Chinstrap Penguin')

which_species(50,20)

which_species(50,15)

which_species(40,23)

which_species(45,20)

which_species(50,23)



"""## Kernel Trick"""

Samplesize = 4
print(df.groupby('species', as_index=False).apply(lambda array: array.loc[np.random.choice(array.index, Samplesize, False),:]))

# Identify the type to exclude
type_to_exclude = 'Adelie'

# Create the logical condition
condition = df['species'] != type_to_exclude

# Filter the dataset
filtered_data = df[condition]

# Drop NaN or None or -Inf values
GenChin_data = filtered_data.dropna()

# Print the filtered dataset
print(GenChin_data)

sns.lmplot(x='flipper_length_mm', y='bill_length_mm', data=GenChin_data, hue='species', palette='Set1', fit_reg=False, scatter_kws={"s":70})

